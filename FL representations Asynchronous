{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817811d-9c88-4036-a944-e649eb546804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import psutil\n",
    "import ray\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", font_scale=1.2, palette=sns.color_palette(\"bright\"), color_codes=False)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'DejaVu Sans'\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889eb74-477d-498f-87a6-8ed02a446a8d",
   "metadata": {},
   "source": [
    "$$\\phi_m(\\theta) = \\frac{1}{2}\\|H_m\\theta - b_m\\|^2$$\n",
    "$$\\nabla \\phi_m(\\theta) = H_m^\\top(H_m\\theta - b_m)$$\n",
    "$$\n",
    "\\begin{align}\n",
    "f_m(\\theta, w) &= \\phi_m(\\theta) + \\frac{1}{2}\\|A_m\\theta+B_mw-y_m\\|^2\\\\\n",
    "\\nabla_1f_m(\\theta, w) &= \\nabla \\phi_m(\\theta) + A_m^\\top(A_m\\theta+B_mw-y_m)\\\\\n",
    "\\nabla_2f_m(\\theta, w) &= B_m^\\top(A_m\\theta+B_mw-y_m)\\\\\n",
    "w_m^*(\\theta) &= (B_m^\\top B_m)^{-1}(B_m^\\top y_m - B_m^\\top A_m\\theta)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54848dee-84f3-4c64-9789-44cf92b5235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A_b(H, n, d, zeta, noise_scale):\n",
    "    A = rng.normal(size=(n, d)) / d\n",
    "    A = H + A/np.linalg.norm(A)\n",
    "    x = rng.normal(size=d)\n",
    "    b = A @ x + noise_scale * rng.normal(n)\n",
    "    return A, b\n",
    "\n",
    "\n",
    "def generate_A_B_c(A, B, n, d1, d2, zeta, noise_scale):\n",
    "    A1 = rng.normal( size=(n, d1), ) / (d1)\n",
    "    B1 = rng.normal( size=(n, d2), ) / (d2)\n",
    "    A = A + zeta*A1/np.linalg.norm(A1)\n",
    "    B = B + zeta*B1/np.linalg.norm(B1)\n",
    "    x1 = rng.normal(size=d1)\n",
    "    x2 = rng.normal(size=d2)\n",
    "    y = A @ x1 + B @ x2 + noise_scale * rng.normal(n)\n",
    "    return A, B, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f69c4a-0ece-43e3-95fe-54f44a3c487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class ParameterServer(object):\n",
    "    def __init__(self, lr, asynchronous, d_theta):\n",
    "        self.x = np.zeros(d_theta)\n",
    "        self.lr = lr\n",
    "        self.asynchronous = asynchronous\n",
    "\n",
    "    def apply_gradients(self, update, *updates):\n",
    "        if self.asynchronous:\n",
    "            self.x -= self.lr * update\n",
    "        else:\n",
    "            summed_updates = np.sum(updates, axis=0)\n",
    "            self.x -= self.lr * summed_updates\n",
    "\n",
    "        return self.x\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.x\n",
    "    \n",
    "    def update_lr(self, lr_coef_mul=1, lr_new=None):\n",
    "        if lr_new is not None:\n",
    "            self.lr = lr_new\n",
    "        else:\n",
    "            self.lr *= lr_coef_mul\n",
    "        \n",
    "    def get_hyperparams(self):\n",
    "        return self.lr, self.asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd53c0f-c677-4198-b1da-b7e7473cc41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_grad(idx, list_Hm_bm, theta):\n",
    "    (Hm, bm) = list_Hm_bm[idx]\n",
    "    return Hm.T@(Hm@theta - bm)\n",
    "\n",
    "def grad_theta(idx, list_Hm_bm, list_Am_Bm_ym, theta, w):\n",
    "    (Am, Bm, ym) = list_Am_Bm_ym[idx]\n",
    "    return phi_grad(idx, list_Hm_bm, theta) + Am.T@(Am@theta + Bm@w - ym)\n",
    "\n",
    "def grad_w(idx, list_Am_Bm_ym, theta, w):\n",
    "    (Am, Bm, ym) = list_Am_Bm_ym[idx]\n",
    "    return Bm.T@(Am@theta + Bm@w - ym)\n",
    "\n",
    "def opt_w(idx, list_Am_Bm_ym, theta):\n",
    "    (Am, Bm, ym) = list_Am_Bm_ym[idx]\n",
    "    A = Bm.T@Bm\n",
    "    b = Bm.T@(ym - Am@theta)\n",
    "    return np.linalg.solve(A, b)\n",
    "\n",
    "def operator(idx, list_Hm_bm, list_Am_Bm_ym, theta):\n",
    "    w_star = opt_w(idx, list_Am_Bm_ym, theta)\n",
    "    return grad_theta(idx, list_Hm_bm, list_Am_Bm_ym, theta, w_star)\n",
    "\n",
    "def evaluate(d_theta, list_Hm_bm, list_Am_Bm_ym, theta):\n",
    "    out = np.zeros((d_theta,))\n",
    "    for m in range(len(list_Hm_bm)):\n",
    "        out += operator(m, list_Hm_bm, list_Am_Bm_ym, theta)\n",
    "    return sum((out / len(list_Hm_bm))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3ba43-cde5-4a2e-b8d2-cb244a2340d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_operator(idx, theta):\n",
    "    w_star = opt_sol(idx, theta)\n",
    "    return grad_1(theta, w_star)\n",
    "\n",
    "def operator_norm_(theta):\n",
    "    return sum(local_operator(theta)**2)\n",
    "\n",
    "@ray.remote\n",
    "class DataWorker(object):\n",
    "    \"\"\"\n",
    "    The class for an individual Ray worker.\n",
    "    Arguments:\n",
    "        lr (float): the stepsize to be used at initialization\n",
    "        label (int, optional): batch size for sampling gradients (default: 1)\n",
    "        seed (int, optional): random seed to generate random variables for reproducibility (default: 0)\n",
    "        bad_worker (bool, optional): if True, the worker will be forced to be slower than others (default: False)\n",
    "    \"\"\"\n",
    "    def __init__(self, idx, lr, n, d_theta, d_w, tau, list_Hm_bm, list_Am_Bm_ym, w0, exact_comp=False, bad_worker=False, seed=0):\n",
    "        self.m = idx\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.lrin = lr\n",
    "        self.d_theta = d_theta\n",
    "        self.d_w = d_w\n",
    "        self.bad_worker = bad_worker\n",
    "        self.exact_comp = exact_comp\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        #self.Hm, self.bm = generate_A_b(H, n, d_theta, zeta, noise_scale)\n",
    "        (self.Hm, self.bm)  = list_Hm_bm[idx]\n",
    "        (self.Am, self.Bm, self.ym) = list_Am_Bm_ym[idx]\n",
    "        self.w0 = w0\n",
    "        #self.Am, self.Bm, self.ym = generate_A_B_c(A, B, n, d_theta, d_w, zeta, noise_scale)\n",
    "\n",
    "    def grad_1(self, theta, w):\n",
    "        return self.Hm.T@(self.Hm@theta - self.bm) + self.Am.T@(self.Am@theta + self.Bm@w - self.ym)\n",
    "    \n",
    "    def grad_2(self, theta, w):\n",
    "        return self.Bm.T@(self.Am@theta + self.Bm@w - self.ym)\n",
    "    \n",
    "    def opt_sol(self, theta):\n",
    "        A = self.Bm.T@self.Bm\n",
    "        b = self.Bm.T@(self.ym - self.Am@theta)\n",
    "        return np.linalg.solve(A, b)\n",
    "\n",
    "    def compute_gradients(self, theta):\n",
    "        t0 = time.perf_counter()\n",
    "        if not self.exact_comp:\n",
    "            w = self.w0.copy()\n",
    "            for t_local in range(self.tau):\n",
    "                grad = self.grad_2( theta, w)\n",
    "                w -= self.lrin*grad\n",
    "    \n",
    "            grad_theta = self.grad_1(theta, w)\n",
    "        else:\n",
    "            w_star = self.opt_sol(theta)\n",
    "            grad_theta = self.grad_1(theta, w_star)\n",
    "            \n",
    "        \n",
    "        if self.bad_worker:\n",
    "            dt = time.perf_counter() - t0\n",
    "            time.sleep(100 * dt)\n",
    "\n",
    "        return grad_theta\n",
    "    \n",
    "    def update_lr(self, lr_coef_mul=1, lr_new=None):\n",
    "        if lr_new is not None:\n",
    "            self.lr = lr_new\n",
    "        else:\n",
    "            self.lr *= lr_coef_mul\n",
    "        \n",
    "    def get_hyperparams(self):\n",
    "        return self.lr, self.batch_size\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9c185-1c52-4cc1-a0de-606bca732b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(seeds, num_workers, lrout, lrin, list_Hm_bm, list_Am_Bm_ym, lr_decay=0, iterations=200, asynchronous=True, delay_adaptive=False, it_check=20, \n",
    "        n=1000, d_theta=100, d_w=50, tau=20, exact_comp=False,\n",
    "        one_bad_worker=False):\n",
    "    delays_all = []\n",
    "    worker_updates = [0 for i in range(num_workers)]\n",
    "    rng = np.random.default_rng(42)\n",
    "    seeds_workers = [rng.choice(max_seed, size=1, replace=False)[0] for _ in range(num_workers)]\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    ps = ParameterServer.remote(lrout, asynchronous, d_theta)\n",
    "    workers = []\n",
    "    for i in range(num_workers):\n",
    "        workers.append(DataWorker.remote(idx=i, lr=lrin, n=n, d_theta=d_theta, d_w=d_w, tau=tau, \n",
    "                                 list_Hm_bm=list_Hm_bm, list_Am_Bm_ym=list_Am_Bm_ym, w0=np.zeros((d_w,)),\n",
    "                                 seed=seeds_workers[i], exact_comp=exact_comp))\n",
    "   # workers = [ for i in range(num_workers)]\n",
    "\n",
    "    x = ps.get_x.remote()\n",
    "    if asynchronous:\n",
    "        gradients = {}\n",
    "        worker_last_it = [0 for _ in range(num_workers)]\n",
    "        worker_id_to_num = {}\n",
    "        for e, worker in enumerate(workers):\n",
    "            gradients[worker.compute_gradients.remote(x)] = worker\n",
    "            worker_id_to_num[worker] = e\n",
    "\n",
    "\n",
    "    losses = []\n",
    "    its = []\n",
    "    ts = []\n",
    "    delays = []\n",
    "    t0 = time.perf_counter()\n",
    "    delay = 0\n",
    "    trace = []\n",
    "    grads_per_it = 1 if asynchronous else num_workers\n",
    "\n",
    "    for it in range(iterations * (num_workers if asynchronous else 1)):\n",
    "        n_grads = it * grads_per_it\n",
    "        if asynchronous:\n",
    "            ready_gradient_list, _ = ray.wait(list(gradients))\n",
    "            ready_gradient_id = ready_gradient_list[-1]\n",
    "            worker = gradients.pop(ready_gradient_id)\n",
    "\n",
    "            # Compute and apply gradients.\n",
    "            gradients[worker.compute_gradients.remote(x)] = worker\n",
    "            worker_num = worker_id_to_num[worker]\n",
    "            delay = it - worker_last_it[worker_num]\n",
    "            if delay_adaptive:\n",
    "                lr_new = lr * num_workers / max(num_workers, delay)\n",
    "                ps.update_lr.remote(lr_new=lr_new)\n",
    "            x = ps.apply_gradients.remote(update=ready_gradient_id)\n",
    "            worker_last_it[worker_num] = it\n",
    "            worker_updates[worker_num] += 1\n",
    "        else:\n",
    "            gradients = [\n",
    "                worker.compute_gradients.remote(x) for worker in workers\n",
    "            ]\n",
    "            # Calculate update after all gradients are available.\n",
    "            x = ps.apply_gradients.remote(None, *gradients)\n",
    "\n",
    "        if it % it_check == 0 or (not asynchronous and it % (max(it_check // num_workers, 1)) == 0):\n",
    "            # Evaluate the current model.\n",
    "            x = ray.get(ps.get_x.remote())\n",
    "            trace.append(x.copy())\n",
    "            its.append(it)\n",
    "            ts.append(time.perf_counter() - t0)\n",
    "\n",
    "        lr_new = lrout / (1 + lr_decay * n_grads)\n",
    "        ps.update_lr.remote(lr_new=lr_new)\n",
    "        t = time.perf_counter()\n",
    "        if asynchronous:\n",
    "            delays.append(delay)\n",
    "\n",
    "    ray.shutdown()\n",
    "    return np.asarray(its), np.asarray(ts), np.asarray([evaluate(d_theta, list_Hm_bm, list_Am_Bm_ym, x) for x in trace]), np.asarray(delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6dc7b-c32b-4bf9-8c1c-f6426c7e1e32",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fbbe1-46d9-4773-9c34-5e68bc2d0ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "psutil.cpu_count(logical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f6164-3798-4373-adb4-0f08eca29717",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 800\n",
    "num_workers = 40\n",
    "\n",
    "d_theta = 400\n",
    "d_w = 50\n",
    "n_data = 10000\n",
    "\n",
    "lmb = 0\n",
    "zeta = 10\n",
    "tau = 10\n",
    "noise_scale = 1e-3\n",
    "\n",
    "M = num_workers\n",
    "it_check = 40\n",
    "n_seeds = 5\n",
    "max_seed = 424242\n",
    "rng = np.random.default_rng(42)\n",
    "seeds = [rng.choice(max_seed, size=1, replace=False)[0] for _ in range(n_seeds)]\n",
    "seed_to_run = {}\n",
    "for r, seed in enumerate(seeds):\n",
    "    seed_to_run[seed] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff377bf-23a5-46b2-a1c0-f5c36c9c6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = rng.uniform(size=(n_data, d_theta)) / d_theta\n",
    "A = rng.uniform(size=(n_data, d_theta)) / d_theta\n",
    "B = rng.uniform(size=(n_data, d_w)) / d_w\n",
    "\n",
    "list_Hm_bm = [generate_A_b(H, n_data, d_theta, zeta, noise_scale) for m in range(M)]\n",
    "list_Am_Bm_ym = [generate_A_B_c(A, B, n_data, d_theta, d_w, zeta, noise_scale) for m in range(M)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857b238-a72d-4e4b-aaed-56d72d8fc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrout_sync = 1 / 325\n",
    "lrin_sync = 1 / 180\n",
    "\n",
    "lr_decay = 0\n",
    "its_, ts_, losses_, _ = run(seeds, num_workers, lrout=lrout_sync, lrin=lrin_sync, list_Hm_bm=list_Hm_bm, list_Am_Bm_ym=list_Am_Bm_ym, \n",
    "                            lr_decay=lr_decay, iterations=iterations, \n",
    "                            asynchronous=False, delay_adaptive=False, it_check=it_check, \n",
    "                            n=n_data, d_theta=d_theta, d_w=d_w, tau=tau,\n",
    "                            one_bad_worker=False, exact_comp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68760ff-dd40-4a52-9a3f-c48cf8fca8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5af44c-ec34-40e4-8995-9b43c51fb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrout_async = 1 / 325\n",
    "lrin_async = 1 / 180\n",
    "\n",
    "lr_decay = 0\n",
    "its_as_, ts_as_, losses_as_, delays = run(seeds, num_workers, lrout=lrout_async, lrin=lrin_async, list_Hm_bm=list_Hm_bm, list_Am_Bm_ym=list_Am_Bm_ym, \n",
    "                            lr_decay=lr_decay, iterations=iterations, \n",
    "                            asynchronous=True, delay_adaptive=False, it_check=it_check, \n",
    "                            n=n_data, d_theta=d_theta, d_w=d_w, tau=tau, exact_comp=True,\n",
    "                            one_bad_worker=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c812c6-cba1-4749-8271-62684ced391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses_as_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175929b-6fd4-427e-bbb3-1e44bc7ac12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4c653-f405-47ae-b421-51ec88bb43f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61088e1-97d9-4f22-8338-856f74a9156d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
